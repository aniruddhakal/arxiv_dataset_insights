{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac52aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from logging import Logger, StreamHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fecb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e49fb11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arxiv-metadata-oai-snapshot.json',\n",
       " 'cache_dir',\n",
       " 'data',\n",
       " 'lemmatized_test_df_dataset_1.pq',\n",
       " 'lemmatized_test_df_dataset_2.pq',\n",
       " 'lemmatized_test_df_dataset_3.pq',\n",
       " 'lemmatized_test_df_dataset_4.pq',\n",
       " 'lemmatized_test_df_dataset_5.pq',\n",
       " 'lemmatized_train_df_dataset_1.pq',\n",
       " 'lemmatized_train_df_dataset_2.pq',\n",
       " 'lemmatized_train_df_dataset_3.pq',\n",
       " 'lemmatized_train_df_dataset_4.pq',\n",
       " 'lemmatized_train_df_dataset_5.pq',\n",
       " 'lemmatized_validation_df_dataset_1.pq',\n",
       " 'lemmatized_validation_df_dataset_2.pq',\n",
       " 'lemmatized_validation_df_dataset_3.pq',\n",
       " 'lemmatized_validation_df_dataset_4.pq',\n",
       " 'lemmatized_validation_df_dataset_5.pq',\n",
       " 'outliers_df.pq',\n",
       " 'parquet',\n",
       " 'split-test_dataset-1_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-test_dataset-1_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-test_dataset-1_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-validation_dataset-4_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-validation_dataset-4_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-validation_dataset-4_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-validation_dataset-5_model-allenai_scibert_scivocab_uncased_embeddings.npy',\n",
       " 'split-validation_dataset-5_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-validation_dataset-5_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-validation_dataset-5_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-validation_dataset-5_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'test_df_dataset_1.pq',\n",
       " 'test_df_dataset_2.pq',\n",
       " 'test_df_dataset_3.pq',\n",
       " 'test_df_dataset_4.pq',\n",
       " 'test_df_dataset_5',\n",
       " 'test_df_dataset_5.pq',\n",
       " 'split-test_dataset-4_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-test_dataset-4_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-test_dataset-4_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-test_dataset-5_model-allenai_scibert_scivocab_uncased_embeddings.npy',\n",
       " 'split-test_dataset-5_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-train_dataset-1_model-allenai_scibert_scivocab_uncased_embeddings.npy',\n",
       " 'split-train_dataset-1_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-train_dataset-1_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-train_dataset-1_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-train_dataset-1_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-train_dataset-2_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-test_dataset-1_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-test_dataset-4_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-train_dataset-2_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-train_dataset-4_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-validation_dataset-2_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-validation_dataset-4_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'train_df_dataset_1.pq',\n",
       " 'split-train_dataset-4_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-train_dataset-4_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-train_dataset-4_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-train_dataset-5_model-allenai_scibert_scivocab_uncased_embeddings.npy',\n",
       " 'split-train_dataset-5_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-train_dataset-5_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-train_dataset-5_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-train_dataset-5_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-validation_dataset-1_model-allenai_scibert_scivocab_uncased_embeddings.npy',\n",
       " 'split-validation_dataset-1_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-validation_dataset-1_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-validation_dataset-1_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-validation_dataset-1_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-validation_dataset-2_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-validation_dataset-2_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-validation_dataset-2_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-validation_dataset-3_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-validation_dataset-3_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-validation_dataset-3_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-validation_dataset-3_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-train_dataset-2_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-train_dataset-2_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-train_dataset-3_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-train_dataset-3_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-train_dataset-3_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-train_dataset-3_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'train_df_dataset_2.pq',\n",
       " 'train_df_dataset_3.pq',\n",
       " 'train_df_dataset_4.pq',\n",
       " 'train_df_dataset_5',\n",
       " 'train_df_dataset_5.pq',\n",
       " 'validation_df_dataset_1.pq',\n",
       " 'validation_df_dataset_2.pq',\n",
       " 'validation_df_dataset_3.pq',\n",
       " 'validation_df_dataset_4.pq',\n",
       " 'validation_df_dataset_5',\n",
       " 'validation_df_dataset_5.pq',\n",
       " 'split-test_dataset-2_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-test_dataset-2_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-test_dataset-2_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-test_dataset-2_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy',\n",
       " 'split-test_dataset-3_model-distilbert-base-nli-mean-tokens_embeddings.npy',\n",
       " 'split-test_dataset-3_model-sentence-transformers_distilbert-base-nli-stsb-quora-ranking_embeddings.npy',\n",
       " 'split-test_dataset-3_model-sentence-transformers_distilroberta-base-paraphrase-v1_embeddings.npy',\n",
       " 'split-test_dataset-3_model-sentence-transformers_stsb-distilroberta-base-v2_embeddings.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3f2887",
   "metadata": {},
   "source": [
    "### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac74641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_index = 5\n",
    "model_name = \"sentence-transformers/distilroberta-base-paraphrase-v1\"\n",
    "splits = ['train', 'validation', 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8ab46",
   "metadata": {},
   "source": [
    "### Load saved embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb8ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def load_embeddings(split_name: str, model_name: str):\n",
    "    embeddings_filename = get_embeddings_filename(split_name, model_name=model_name)\n",
    "\n",
    "    if Path(embeddings_filename).exists():\n",
    "        try:\n",
    "            embeddings = np.load(embeddings_filename)\n",
    "        except FileNotFoundError as e:\n",
    "            logger.error(f\"Expected file named {embeddings_filename} was not found\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_filename(split_name, model_name):\n",
    "    model_normalized_name = re.sub(\"/\", \"_\", model_name)\n",
    "    \n",
    "    return str(\n",
    "        dataset_path /\n",
    "        f\"split-{split_name}_dataset-{dataset_index}_model-{model_normalized_name}_embeddings.npy\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f208f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112830, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_embeddings = load_embeddings(split_name='train', model_name=model_name)\n",
    "train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc77a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112830, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_embeddings = load_embeddings(split_name='validation', model_name=model_name)\n",
    "validation_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150f000",
   "metadata": {},
   "source": [
    "### Prepare labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab5a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = dataset_path / 'cache_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc33820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def load_target_dataset(split: str, dataset_index: int = None):\n",
    "    prefix = \"\"\n",
    "\n",
    "    dataset = \\\n",
    "        load_dataset('parquet',\n",
    "                     data_files=[str(dataset_path / f\"{split}_df_dataset_{dataset_index}.pq\")],\n",
    "                     cache_dir=cache_dir)['train']\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b2bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/mnt/NVMe/workspace/github_projects/arxiv_dataset_insights/apps/classifier/../../dataset/cache_dir/parquet/default-a97d8722ee27f6d5/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69e5515315e430a94d758e008d41a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/mnt/NVMe/workspace/github_projects/arxiv_dataset_insights/apps/classifier/../../dataset/cache_dir/parquet/default-64457f2740b93e09/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba2379c640d4f0a9edf5c46ddd23819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/mnt/NVMe/workspace/github_projects/arxiv_dataset_insights/apps/classifier/../../dataset/cache_dir/parquet/default-6d7d74b312461a4f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f791f3c159445348a85d555d7165eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_target_dataset(split='train', dataset_index=dataset_index)\n",
    "validation_dataset = load_target_dataset(split='validation', dataset_index=dataset_index)\n",
    "test_dataset = load_target_dataset(split='test', dataset_index=dataset_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c489c62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112830, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings = load_embeddings(split_name='test', model_name=model_name)\n",
    "test_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b406ff9",
   "metadata": {},
   "source": [
    "### This does not include 2 categories that are missing from dataset 5 due to them being minor categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34774301",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = train_dataset['categories_list']\n",
    "categories_list.extend(validation_dataset['categories_list'])\n",
    "categories_list.extend(test_dataset['categories_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b2c6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unique_categories = set()\n",
    "\n",
    "[all_unique_categories.update(x) for x in train_dataset['categories_list']]\n",
    "all_unique_categories = list(all_unique_categories)\n",
    "len(all_unique_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88df54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfba2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer(sparse_output=False)\n",
    "_ = multilabel_binarizer.fit_transform(train_dataset['categories_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ee6223a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multilabel_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a9f167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = Path('../../models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c80a9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f21da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(models_dir / 'multilabel_binarizer.pkl', 'wb') as f:\n",
    "    pickle.dump(multilabel_binarizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "814e773b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(models_dir / 'multilabel_binarizer.pkl', 'rb') as f:\n",
    "    multilabel_binarizer = pickle.load(f)\n",
    "len(multilabel_binarizer.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ba093a",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5fc80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def transform_labels(labels: List[List[str]]):\n",
    "    y = multilabel_binarizer.transform(labels)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1acba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112830, 174)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = transform_labels(train_dataset['categories_list'])\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a8d9d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112830, 174)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y = transform_labels(validation_dataset['categories_list'])\n",
    "validation_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6193f6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112830, 174)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = transform_labels(test_dataset['categories_list'])\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad343b",
   "metadata": {},
   "source": [
    "### Build a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4632e8a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (0.4.12)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (4.23.2)\n",
      "Requirement already satisfied: setuptools in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (67.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (6.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.20.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /mnt/NVMe2/VirtualEnvironments/general_python_venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44485ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "838d8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdf289f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 23:53:24.649446: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-13 23:53:24.695435: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-13 23:53:24.696320: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-13 23:53:25.867790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-06-13 23:53:27.362384: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-13 23:53:27.398859: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf   # TensorFlow registers PluggableDevices here.\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abbf53b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dim = train_embeddings.shape[1]\n",
    "out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def get_dense_model(num_classes: int):\n",
    "    # Define the model architecture\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(512, activation='relu', input_shape=(768,)),\n",
    "        keras.layers.Dense(256, activation='relu'),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='sigmoid')  # Using sigmoid activation for multi-label classification\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c682eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_dense_model(num_classes=len(multilabel_binarizer.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a69bfb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_11 (Dense)            (None, 512)               393728    \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 174)               22446     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 580,398\n",
      "Trainable params: 580,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b855fd9",
   "metadata": {},
   "source": [
    "### Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6077e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'f1_score', 'jaccard_score'])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c5fe23e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "147/147 [==============================] - 4s 25ms/step - loss: 0.0832 - accuracy: 0.0938 - val_loss: 0.0399 - val_accuracy: 0.1937\n",
      "Epoch 2/100\n",
      "147/147 [==============================] - 3s 22ms/step - loss: 0.0344 - accuracy: 0.2568 - val_loss: 0.0312 - val_accuracy: 0.3068\n",
      "Epoch 3/100\n",
      "147/147 [==============================] - 3s 22ms/step - loss: 0.0297 - accuracy: 0.3294 - val_loss: 0.0288 - val_accuracy: 0.3430\n",
      "Epoch 4/100\n",
      "147/147 [==============================] - 3s 22ms/step - loss: 0.0279 - accuracy: 0.3598 - val_loss: 0.0275 - val_accuracy: 0.3685\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 768\n",
    "epochs = 100\n",
    "model.fit(train_embeddings, train_y, batch_size=batch_size, epochs=epochs,\n",
    "          validation_data=(validation_embeddings, validation_y))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "449a318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf   # TensorFlow registers PluggableDevices here.\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5c24d",
   "metadata": {},
   "source": [
    "### Evaluate a classifier on test dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
